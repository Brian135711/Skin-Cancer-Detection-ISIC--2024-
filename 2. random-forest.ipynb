{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":79795,"sourceType":"modelInstanceVersion","modelInstanceId":67049,"modelId":91270}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, average_precision_score, precision_recall_curve\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-31T17:20:49.063854Z","iopub.execute_input":"2024-07-31T17:20:49.064222Z","iopub.status.idle":"2024-07-31T17:20:49.070222Z","shell.execute_reply.started":"2024-07-31T17:20:49.064195Z","shell.execute_reply":"2024-07-31T17:20:49.069044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\ndirname = '/kaggle/input/isic-2024-challenge/'\n# Get the working directory\nworking_dir = '/kaggle/working/'\n\n# Explicitly specify data types for the columns with mixed types\ndtype_dict = {\n    51: str,   # Replace 51 with the actual column name\n    52: str,   # Replace 52 with the actual column name\n}\ntrain_meta = pd.read_csv(os.path.join(dirname,'train-metadata.csv'), dtype = dtype_dict)\ntest_meta = pd.read_csv(os.path.join(dirname,'test-metadata.csv'), dtype = dtype_dict)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:20:56.345458Z","iopub.execute_input":"2024-07-31T17:20:56.345871Z","iopub.status.idle":"2024-07-31T17:21:02.167666Z","shell.execute_reply.started":"2024-07-31T17:20:56.345840Z","shell.execute_reply":"2024-07-31T17:21:02.166391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get common columns, excluding 'target' from the comparison\ncommon_columns = [col for col in train_meta.columns if col in test_meta.columns or col == 'target']\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:02.169299Z","iopub.execute_input":"2024-07-31T17:21:02.169680Z","iopub.status.idle":"2024-07-31T17:21:02.175274Z","shell.execute_reply.started":"2024-07-31T17:21:02.169650Z","shell.execute_reply":"2024-07-31T17:21:02.174068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter both DataFrames to keep only common columns\ntrain_meta = train_meta[common_columns]\ntest_meta = test_meta[[col for col in common_columns if col != 'target']] ","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:26.699542Z","iopub.execute_input":"2024-07-31T17:21:26.700329Z","iopub.status.idle":"2024-07-31T17:21:26.805600Z","shell.execute_reply.started":"2024-07-31T17:21:26.700290Z","shell.execute_reply":"2024-07-31T17:21:26.804449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define columns to exclude from imputation\ncolumns_to_exclude = ['isic_id', 'patient_id',\n                      'attribution', 'copyright_license','image_type','tbp_tile_type','tbp_lv_location','tbp_lv_location_simple'] \n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:29.746559Z","iopub.execute_input":"2024-07-31T17:21:29.746957Z","iopub.status.idle":"2024-07-31T17:21:29.751675Z","shell.execute_reply.started":"2024-07-31T17:21:29.746929Z","shell.execute_reply":"2024-07-31T17:21:29.750583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Identify potential features: Get all column names\nall_columns = train_meta.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:33.781006Z","iopub.execute_input":"2024-07-31T17:21:33.781385Z","iopub.status.idle":"2024-07-31T17:21:33.786035Z","shell.execute_reply.started":"2024-07-31T17:21:33.781356Z","shell.execute_reply":"2024-07-31T17:21:33.785007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Filter numerical features: Exclude the columns_to_exclude and 'target'\nnum_meta_cols = [col for col in all_columns if (train_meta[col].dtype in [np.number, 'Int64']) and col not in columns_to_exclude and col != 'target']  # Exclude 'target'\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:36.584401Z","iopub.execute_input":"2024-07-31T17:21:36.585206Z","iopub.status.idle":"2024-07-31T17:21:36.592779Z","shell.execute_reply.started":"2024-07-31T17:21:36.585170Z","shell.execute_reply":"2024-07-31T17:21:36.591801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Filter categorical features: Exclude the columns_to_exclude\ncat_meta_cols = [col for col in all_columns if (train_meta[col].dtype == 'object' or train_meta[col].dtype.name == 'category') and col not in columns_to_exclude]  \n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:48.986240Z","iopub.execute_input":"2024-07-31T17:21:48.986652Z","iopub.status.idle":"2024-07-31T17:21:48.992775Z","shell.execute_reply.started":"2024-07-31T17:21:48.986619Z","shell.execute_reply":"2024-07-31T17:21:48.991651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate features (X) and target (y)\nX = train_meta.drop(columns=['target'] + columns_to_exclude)\ny = train_meta['target']\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:52.471121Z","iopub.execute_input":"2024-07-31T17:21:52.471480Z","iopub.status.idle":"2024-07-31T17:21:52.519999Z","shell.execute_reply.started":"2024-07-31T17:21:52.471453Z","shell.execute_reply":"2024-07-31T17:21:52.519134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features for the test set (exclude 'target' since it's not there)\nX_test = test_meta.drop(columns=columns_to_exclude) \n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:56.025992Z","iopub.execute_input":"2024-07-31T17:21:56.026384Z","iopub.status.idle":"2024-07-31T17:21:56.032537Z","shell.execute_reply.started":"2024-07-31T17:21:56.026355Z","shell.execute_reply":"2024-07-31T17:21:56.031209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define preprocessing pipeline for numerical columns\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median'))])  # Use median for numerical imputation\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:21:58.553750Z","iopub.execute_input":"2024-07-31T17:21:58.554220Z","iopub.status.idle":"2024-07-31T17:21:58.560943Z","shell.execute_reply.started":"2024-07-31T17:21:58.554177Z","shell.execute_reply":"2024-07-31T17:21:58.559493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define preprocessing pipeline for categorical columns\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot',\n OneHotEncoder(handle_unknown='ignore'))]) \n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:01.162869Z","iopub.execute_input":"2024-07-31T17:22:01.163266Z","iopub.status.idle":"2024-07-31T17:22:01.168752Z","shell.execute_reply.started":"2024-07-31T17:22:01.163235Z","shell.execute_reply":"2024-07-31T17:22:01.167233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the full pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, num_meta_cols),\n        ('cat', categorical_transformer, cat_meta_cols)])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:04.244290Z","iopub.execute_input":"2024-07-31T17:22:04.244694Z","iopub.status.idle":"2024-07-31T17:22:04.250764Z","shell.execute_reply.started":"2024-07-31T17:22:04.244661Z","shell.execute_reply":"2024-07-31T17:22:04.249633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing to the train set\nX_processed = preprocessor.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:06.853707Z","iopub.execute_input":"2024-07-31T17:22:06.854593Z","iopub.status.idle":"2024-07-31T17:22:10.355404Z","shell.execute_reply.started":"2024-07-31T17:22:06.854528Z","shell.execute_reply":"2024-07-31T17:22:10.354441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the same preprocessing to the test set\nX_test_processed = preprocessor.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:10.357009Z","iopub.execute_input":"2024-07-31T17:22:10.357353Z","iopub.status.idle":"2024-07-31T17:22:10.369239Z","shell.execute_reply.started":"2024-07-31T17:22:10.357317Z","shell.execute_reply":"2024-07-31T17:22:10.368022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:16.693582Z","iopub.execute_input":"2024-07-31T17:22:16.693977Z","iopub.status.idle":"2024-07-31T17:22:16.872903Z","shell.execute_reply.started":"2024-07-31T17:22:16.693947Z","shell.execute_reply":"2024-07-31T17:22:16.871823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, min_tpr: float=0.80) -> float:\n    '''\n    2024 ISIC Challenge metric: pAUC\n    \n    Given a solution file and submission file, this function returns the\n    the partial area under the receiver operating characteristic (pAUC) \n    above a given true positive rate (TPR) = 0.80.\n    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n    \n    (c) 2024 Nicholas R Kurtansky, MSKCC\n\n    Args:\n        solution: ground truth pd.DataFrame of 1s and 0s\n        submission: solution dataframe of predictions of scores ranging [0, 1]\n\n    Returns:\n        Float value range [0, max_fpr]\n    '''\n\n    \n\n    # check submission is numeric\n    if not pd.api.types.is_numeric_dtype(submission.values):\n        raise ParticipantVisibleError('Submission target column must be numeric')\n\n    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n    v_gt = abs(np.asarray(solution.values)-1)\n    \n    # flip the submissions to their compliments\n    v_pred = -1.0*np.asarray(submission.values)\n\n    max_fpr = abs(1-min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n        \n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n\n    return(partial_auc)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:19.259192Z","iopub.execute_input":"2024-07-31T17:22:19.259654Z","iopub.status.idle":"2024-07-31T17:22:19.269372Z","shell.execute_reply.started":"2024-07-31T17:22:19.259618Z","shell.execute_reply":"2024-07-31T17:22:19.268200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def p_auc(y_true, y_pred, min_tpr = 0.80):\n    df = pd.DataFrame({'labels': y_true, 'predictions': y_pred})\n    p_auc_score = score(df[['labels']], df[['predictions']])\n    return p_auc_score\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:23.141398Z","iopub.execute_input":"2024-07-31T17:22:23.142285Z","iopub.status.idle":"2024-07-31T17:22:23.147204Z","shell.execute_reply.started":"2024-07-31T17:22:23.142253Z","shell.execute_reply":"2024-07-31T17:22:23.146123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you want to use the best model based on validation pAUC\nbest_val_pauc = -1\nbest_model = None\nfor n_estimators in [300]:\n    for max_depth in [9]:  #None used to \n        rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, class_weight='balanced', n_jobs =-1)\n        rf_model.fit(X_train, y_train)\n        y_val_pred_proba = rf_model.predict_proba(X_val)[:, 1]\n        pauc = p_auc(y_val, y_val_pred_proba)\n        print(f\"Validation pAUC (n_estimators={n_estimators}, max_depth={max_depth}): {pauc:.4f}\")\n        \n        if pauc > best_val_pauc:\n            best_val_pauc = pauc\n            best_model = rf_model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T17:22:25.779705Z","iopub.execute_input":"2024-07-31T17:22:25.780669Z","iopub.status.idle":"2024-07-31T17:53:49.592990Z","shell.execute_reply.started":"2024-07-31T17:22:25.780631Z","shell.execute_reply":"2024-07-31T17:53:49.591856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set using the best model\ny_test_pred_proba = best_model.predict_proba(X_test_processed)[:, 1]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Create a DataFrame for submission\nsubmission_df = pd.DataFrame({\n    'isic_id': test_meta['isic_id'],  # Use original 'isic_id' values\n    'target': y_test_pred_proba\n})\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Save the submission to a CSV file\n\nsubmission_df.to_csv(os.path.join(working_dir,\"submission.csv\"), index=False)\n","metadata":{},"execution_count":null,"outputs":[]}]}